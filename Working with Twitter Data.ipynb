{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to run the NLTK (natural language toolkit) `download` function to download additional items for using `nltk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_nltk_downloader = False\n",
    "\n",
    "if run_nltk_downloader:\n",
    "    nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in JSON (JavaScript Object Notation) format. The JSON file is compressed to save space. The following code block shows how to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_filepath = pathlib.Path('relevant_data.json.gz')\n",
    "\n",
    "with gzip.GzipFile(raw_data_filepath, 'r') as fp:\n",
    "    json_bytes = fp.read()\n",
    "    json_str = json_bytes.decode('utf-8')\n",
    "    tweet_data = json.loads(json_str)\n",
    "    \n",
    "print(f'The data includes {len(tweet_data)} observations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as a list of lists. Each sublist has six items:\n",
    "1. the datetime for the tweet,\n",
    "2. the username associated with the tweet,\n",
    "3. the user associated with the tweet,\n",
    "4. the location associated with the tweet,\n",
    "5. the language associated with the tweet, and\n",
    "6. the tweet text.\n",
    "\n",
    "The following code block prints the first entry as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block:\n",
    "1. creates a Pandas `DataFrame` with the data (named `tweet_df`),\n",
    "2. converts the `Datetime` column to a datetime format,\n",
    "3. creates a `Date` column with just the date extracted from the `Datetime` column,\n",
    "4. creates a `Day_Name` column that specifies the day of the week that the tweet was posted.\n",
    "5. creates a `Weekend` column that is `True` if the tweet was posted on a weekend, and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    'Datetime',\n",
    "    'Username',\n",
    "    'User',\n",
    "    'Location',\n",
    "    'Language',\n",
    "    'Text',\n",
    "]\n",
    "\n",
    "tweet_df = pd.DataFrame(tweet_data, \n",
    "                        columns = column_names)\n",
    "\n",
    "tweet_df['Datetime'] = pd.to_datetime(tweet_df['Datetime'], \n",
    "                                      format = '%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "tweet_df['Date'] = tweet_df['Datetime'].dt.date\n",
    "\n",
    "tweet_df['Day_Name'] = tweet_df['Datetime'].dt.day_name()\n",
    "\n",
    "weekend_mask = tweet_df['Day_Name'].isin(['Saturday', 'Sunday'])\n",
    "tweet_df.loc[weekend_mask, 'Weekend'] = True\n",
    "tweet_df.loc[~weekend_mask, 'Weekend'] = True\n",
    "\n",
    "tweet_df['Hour'] = tweet_df['Datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows the number of missing values in the data (expressed as a proportion of the total number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.isna().sum()/len(tweet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block plots the number of tweets collected each day (recall this is just a sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (15, 6))\n",
    "\n",
    "temp = tweet_df.groupby(['Date'])['Text'].count().reset_index()\n",
    "temp = temp.rename(columns = {'Text': '# Tweets'})\n",
    "\n",
    "sns.lineplot(\n",
    "    x = 'Date', \n",
    "    y = '# Tweets',\n",
    "    data = temp,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates a plot that shows how the average number of tweets posted a day varies by day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (12, 6))\n",
    "\n",
    "temp = tweet_df.groupby(['Date', 'Day_Name'])['Text'].count().reset_index()\n",
    "temp = temp.groupby(['Day_Name'])['Text'].mean().reset_index()\n",
    "temp = temp.rename(columns = {'Text': '# Tweets (Avg)'})\n",
    "\n",
    "sns.barplot(\n",
    "    x = 'Day_Name', \n",
    "    y = '# Tweets (Avg)',\n",
    "    data = temp,\n",
    "    edgecolor = 'k',\n",
    "    order = ['Monday', \n",
    "             'Tuesday',\n",
    "             'Wednesday',\n",
    "             'Thursday',\n",
    "             'Friday',\n",
    "             'Saturday',\n",
    "             'Sunday',\n",
    "            ]\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates a plot that shows how the average number of tweets posted a day varies by hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (12, 6))\n",
    "\n",
    "temp = tweet_df.groupby(['Date', 'Hour'])['Text'].count().reset_index()\n",
    "temp = temp.groupby(['Hour'])['Text'].mean().reset_index()\n",
    "temp = temp.rename(columns = {'Text': '# Tweets (Avg)'})\n",
    "\n",
    "sns.barplot(\n",
    "    x = 'Hour', \n",
    "    y = '# Tweets (Avg)',\n",
    "    data = temp,\n",
    "    edgecolor = 'k',\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows how we can use `nltk` to get a frequency distribution for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "tweets = tweet_df['Text'].str.lower().tolist()\n",
    "tknzr = nltk.tokenize.TweetTokenizer()\n",
    "tweet_tokens = [tknzr.tokenize(tweet) for tweet in tweets]\n",
    "all_tokens = list(itertools.chain.from_iterable(tweet_tokens))\n",
    "freq_dist = nltk.FreqDist(all_tokens)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Tokenization and frequency distribution construction took {np.round(end_time - start_time, 2)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows the top 30 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist.most_common(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
